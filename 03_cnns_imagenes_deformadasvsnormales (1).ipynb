{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg90deR13qYE"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/044_cnn_transfer_learning/cnn_transfer_learning.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbPNsWiCDJjO"
      },
      "source": [
        "# Transfer Learning en Redes Convolucionales\n",
        "\n",
        "En posts anteriores hemos introducido la arquitectura de `red neuronal convolucional` y también hemos presentado varias arquitecturas famosas que han demostrado buenas prestaciones en multitud de tareas. Estas redes están formadas muchas capas convolucionales, algunas con más de 100 capas, lo cual significa que tienen muchos parámetros y entrenarlas desde cero puedes ser costoso. Sin embargo, existe una técnica que nos permite obtener buenos modelos con menores requisitos: el *transfer learning*. Ya hemos hablado anteriormente de esta técnica, en el contexto de modelos de lenguaje, pero la idea es la misma: utilizaremos el máximo número de capas de una red ya entrenada en otro dataset, y simplemente entrenaremos las nuevas capas que necesitemos para nuestra tarea concreta.\n",
        "\n",
        "![](https://pennylane.ai/qml/_images/transfer_learning_general.png)\n",
        "\n",
        "En este post vamos a ver cómo podemos utilizar una red neuronal pre-entrada en Imagenet, y adaptarla para una nueva tarea de clasificación con un pequeño dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idgJsfvUDJjP"
      },
      "source": [
        "## El dataset\n",
        "\n",
        "Nuestro objetivo será el de entrenar un clasificador de flores. Podemos descargar las imágenes de la siguiente url."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hV9wStiG7g1P"
      },
      "outputs": [],
      "source": [
        "# !pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4HLwRKrDJjP"
      },
      "outputs": [],
      "source": [
        "# import wget \n",
        "\n",
        "# wget.download('https://mymldatasets.s3.eu-de.cloud-object-storage.appdomain.cloud/flowers.zip')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "J5C0kYmgorIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jt9JP32MDJjR"
      },
      "outputs": [],
      "source": [
        "# import zipfile\n",
        "\n",
        "# with zipfile.ZipFile('flowers.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('.')\n",
        "#descomprimimos nuestro data set\n",
        "from zipfile import ZipFile\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/Vegetable Images Redes Convulsionales.zip'\n",
        "with ZipFile(file_path, 'r') as zip:\n",
        "  zip.extractall('.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "conjunto de datos de 15 tipos diferentes de vegetales comúnmente encontrados en todo el mundo. Los 15 tipos de vegetales incluidos en el conjunto de datos son frijoles, calabacín amargo, calabaza en forma de botella, berenjena, brócoli, col, pimiento, zanahoria, coliflor, pepino, papaya, patata, calabaza, rábano y tomate. El conjunto de datos consta de un total de 21,000 imágenes, donde cada clase contiene 1,400 imágenes de tamaño 224 x 224 en formato *.jpg.\n",
        "\n",
        "El conjunto de datos se divide en tres partes para fines de entrenamiento, validación y prueba. El 70% del conjunto de datos se utiliza para el entrenamiento, el 15% se utiliza para la validación y el 15% restante se utiliza para la prueba. Este tipo de división de datos es común en el aprendizaje automático para garantizar que el modelo se entrene con una cantidad suficiente de datos, al tiempo que pueda generalizar bien a nuevos datos no vistos.\n",
        "\n",
        "train (15000 images)\n",
        "test (3000 images)\n",
        "validation (3000 images)"
      ],
      "metadata": {
        "id": "ugGQhLNaqMxJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBmxJrDWDJjS"
      },
      "source": [
        "Una vez extraído el dataset, podemos ver que tenemos 5 clases de flores diferentes, distribuidas en 5 carpetas diferentes. Cada carpeta contiene varios ejemplos de flores de la categoría en cuestión."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "l67h0QFGp6gC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_Rw1OtUDJjS"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "#cargamos nuetro dataset una ves descomprimidad\n",
        "#----------------------------\n",
        "PATH = '/content/Vegetable Images/train'\n",
        "#------------------------\n",
        "classes = os.listdir(PATH)\n",
        "classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK4iOaqsDJjT"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skjEodNlDJjT"
      },
      "outputs": [],
      "source": [
        "imgs, labels = [], []\n",
        "\n",
        "for i, lab in enumerate(classes):\n",
        "  paths = os.listdir(f'{PATH}/{lab}')\n",
        "  print(f'Categoría: {lab}. Imágenes: {len(paths)}')\n",
        "  paths = [p for p in paths if p[-3:] == \"jpg\"]\n",
        "  imgs += [f'{PATH}/{lab}/{img}' for img in paths]\n",
        "  labels += [i]*len(paths)\n",
        "\n",
        "  #visualizacion de nuestras clases que cada uno cuenta con 1000 imagenes que son de entrenamiento haciendo total de 15000 imagenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMTQQeh132aJ"
      },
      "outputs": [],
      "source": [
        "imgs[:5]\n",
        "len(imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXBMon75DJjU"
      },
      "source": [
        "Podemos visualizar algunas imágenes en el dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcW1CMaXDJjV"
      },
      "outputs": [],
      "source": [
        "import random \n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(4,8, figsize=(15,9))\n",
        "for _ax in axs:\n",
        "  for ax in _ax:\n",
        "    ix = random.randint(0, len(imgs)-1)\n",
        "    img = io.imread(imgs[ix])\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "    ax.set_title(classes[labels[ix]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV6vWe7EDJjV"
      },
      "source": [
        "Vamos a crear también un subconjunto de test para poder comparar varios modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xW8j_prSDJjW"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_imgs, test_imgs, train_labels, test_labels = train_test_split(imgs, labels, test_size=0.2, stratify=labels)\n",
        "\n",
        "len(train_imgs), len(test_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dnwGW-NDJjW"
      },
      "source": [
        "Y por último creamos nuestros objetos `Dataset` y `DataLoader` para poder darle las imágenes a nuestros modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fIDk8K7DJjW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, X, y, trans, device):#devide gpu\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.trans = trans\n",
        "    self.device = device\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, ix):\n",
        "    # cargar la imágen\n",
        "    img = io.imread(self.X[ix])#lee la ruta de la  iamgen\n",
        "    # aplicar transformaciones\n",
        "    #print(f\"imagen: {img}\")\n",
        "    if self.trans:#aplica transformaciones si es igual \n",
        "      img = self.trans(image=img)[\"image\"]#verificar y leer las images\n",
        "    return torch.from_numpy(img / 255.).float().permute(2,0,1), torch.tensor(self.y[ix])#devuelve tensores en torh img/255 normaliza la trandormar a  float"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMDaR9MUDJjX"
      },
      "source": [
        "Nos aseguraremos que todas las imágenes del dataset tengan las mismas dimensiones: 224x224 píxeles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOQawbLGDJjX"
      },
      "outputs": [],
      "source": [
        "import albumentations as A #corta todas la images en un tamano especfico\n",
        "#auqnue no fue necesario a causa que nuestro tamano de nuestras imagenes por defecto vienen de 224*224 se hizo un redimensionamiento\n",
        "#para aseguar que nuestras imagenes esten todas del mismo tamano\n",
        "#---------------------------------------------\n",
        "trans = A.Compose([\n",
        "    A.Resize(224,224)#realizamos para que las imagenes estn del mismo tammano es decir de 224*224\n",
        "])\n",
        "\n",
        "dataset = {\n",
        "    'train': Dataset(train_imgs, train_labels, trans, device), \n",
        "    'test': Dataset(test_imgs, test_labels, trans, device)\n",
        "}\n",
        "#---------------------------------------------------\n",
        "\n",
        "len(dataset['train']), len(dataset['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1s0HQqTo6GvM"
      },
      "outputs": [],
      "source": [
        "dataset['train'][2]#accede al tercer elemento de la lista (el índice 2) y devuelve su valor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dr83-HNlDJjX"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(4,6, figsize=(14,8))\n",
        "for _ax in axs:\n",
        "  for ax in _ax:\n",
        "    ix = random.randint(0, len(dataset['train'])-1)\n",
        "    img, lab = dataset['train'][ix]\n",
        "    ax.imshow(img.permute(1,2,0))\n",
        "    ax.axis('off')\n",
        "    ax.set_title(classes[lab])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Klbor3C5DJjY"
      },
      "outputs": [],
      "source": [
        "dataloader = {# se utiliza para cargar datos durante el entrenamiento y la evaluación de un modelo de aprendizaje automático.\n",
        "    'train': torch.utils.data.DataLoader(dataset['train'], batch_size=64, shuffle=True, pin_memory=True), #bach_Size -> número de ejemplos de entrenamiento que se utilizarán en una iteración para ajustar los pesos del modelo.\n",
        "    'test': torch.utils.data.DataLoader(dataset['test'], batch_size=256, shuffle=False)# La opción shuffle=True indica que los ejemplos de entrenamiento se barajarán aleatoriamente antes de dividirlos en lotes, lo que ayuda a garantizar que los lotes de entrenamiento no contengan ejemplos similares. \n",
        " #pin_memory=True es una optimización que permite que los datos se transfieran más rápidamente a la memoria de la GPU durante el entrenamiento, si se está utilizando una GPU.\n",
        "}\n",
        "\n",
        "imgs, labels = next(iter(dataloader['train']))\n",
        "imgs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISvha2LLDJjY"
      },
      "source": [
        "## El Modelo\n",
        "\n",
        "Vamos a escoger la arquitectura `resnet`, de la que ya hablamos en el post anterior, para hacer nuestro clasificador. De este modelo usarmos todas las capas excepto la última, la cual sustituiremos por una nueva capa lineal para llevar a cabo la clasificación en 5 clases."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La principal ventaja de usar ResNet50 en lugar de ResNet18 es que es una red neuronal más profunda, con 50 capas en lugar de 18. Esto permite que ResNet50 aprenda representaciones más complejas y detalladas de las imágenes, lo que puede conducir a una mayor precisión en tareas de clasificación de imágenes. "
      ],
      "metadata": {
        "id": "_ZjHnzGqc9Mi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fku2VHn9DJjZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "#modelos de prueba utilizando resnet50 el objetivo de este modelo para utilizarlo fue que aprenda representaciones más complejas y \n",
        "#detalladas de las imágenes, lo que puede conducir a una mayor precisión en tareas de clasificación de imágenes.\n",
        "\n",
        "import torchvision\n",
        "\n",
        "resnet = torchvision.models.resnet50()\n",
        "resnet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IiSaSokDJjZ"
      },
      "outputs": [],
      "source": [
        "class ModelCustom(torch.nn.Module):#El modelo se construye a partir de una red ResNet-18 pre-entrenada y se agrega una capa lineal en la parte superior para la clasificación final.\n",
        "  def __init__(self, n_outputs=10, pretrained=False, freeze=False):\n",
        "    super().__init__()\n",
        "    # descargamos resnet\n",
        "    resnet = torchvision.models.resnet18(pretrained=pretrained)\n",
        "    # nos quedamos con todas las capas menos la última\n",
        "    self.resnet = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
        "    if freeze:\n",
        "      for param in self.resnet.parameters():\n",
        "        param.requires_grad=False\n",
        "    # añadimos una nueva capa lineal para llevar a cabo la clasificación\n",
        "    #-----------------------------------------------adecuamos los datos para el modelo con 15 salidad correspondientes a nuestros clases\n",
        "    self.fc = torch.nn.Linear(512, 15)\n",
        "\n",
        "  def forward(self, x):#resnet son los pesos,El método forward define la operación de propagación hacia adelante del modelo. Primero se pasa la entrada x a través de la red ResNet-18 y se aplana en un tensor de dos dimensiones. Luego, el tensor se pasa a través de una capa lineal para producir las salidas del modelo.\n",
        "    x = self.resnet(x)\n",
        "    x = x.view(x.shape[0], -1)#tranformacion en un numero de baches\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "  def unfreeze(self):#El método unfreeze permite descongelar las capas de la red ResNet-18 para el entrenamiento de fine-tuning,\n",
        "    for param in self.resnet.parameters():\n",
        "        param.requires_grad=True#descongela la gradientes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAvZN3M8DJja"
      },
      "outputs": [],
      "source": [
        "model_custom = ModelCustom()\n",
        "outputs = model_custom(torch.randn(64, 3, 224, 224))\n",
        "outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDhYXGefDJja"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def fit(model, dataloader, epochs=5, lr=1e-2):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        train_loss, train_acc = [], []\n",
        "        bar = tqdm(dataloader['train'])\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "            train_acc.append(acc)\n",
        "            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n",
        "        bar = tqdm(dataloader['test'])\n",
        "        val_loss, val_acc = [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in bar:\n",
        "                X, y = batch\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                y_hat = model(X)\n",
        "                loss = criterion(y_hat, y)\n",
        "                val_loss.append(loss.item())\n",
        "                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "                val_acc.append(acc)\n",
        "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
        "        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
        "  #--------------------------------------------------------------------------------------   \n",
        "        # Guardar checkpoint en c\n",
        "        checkpoint_path = f\"checkpoint_epoch_{epoch}.pth\"\n",
        "        torch.save({\n",
        "            'epoch': epoch, #el número de la época actual\n",
        "            'model_state_dict': model.state_dict(),# diccionario que contiene los pesos del modelo actual\n",
        "            'optimizer_state_dict': optimizer.state_dict(),#un diccionario que contiene el estado actual del optimizador.\n",
        "            'loss': loss, #el valor de pérdida del último batch del entrenamiento.\n",
        "        }, checkpoint_path)\n",
        "  #----------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFT1nukKDJja"
      },
      "source": [
        "### Entrenando desde cero\n",
        "\n",
        "En primer lugar vamos a entrenar nuestro modelo desde cero para ver qué métricas podemos obtener.\n",
        "\n",
        "las activaciones son el resultado de aplicar una transformación no lineal a la suma ponderada de las entradas y los pesos de la capa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jd5JvPKADJjb"
      },
      "outputs": [],
      "source": [
        "model_c = ModelCustom()\n",
        "fit(model_c, dataloader, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOIT9K6DDJjb"
      },
      "source": [
        "se lleva a cabo durante 15 épocas y durante la última época, la pérdida de entrenamiento es 0.04503, la pérdida de validación es 0.08641, la precisión de entrenamiento es 0.98820 y la precisión de validación es 0.97482.\n",
        "\n",
        "Como puedes ver es complicado conseguir buenas métricas ya que nuestro dataset es muy pequeño."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDZJlruKDJjb"
      },
      "source": [
        "## Transfer Learning\n",
        "\n",
        "es una técnica muy utilizada en el campo del aprendizaje profundo que permite reutilizar el conocimiento aprendido por una red neuronal en una tarea específica y aplicarlo a otra tarea relacionada.\n",
        "\n",
        "Ahora vamos a entrenar el mismo caso pero, en este caso, utilizando los pesos pre-entrenados de `resnet`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhQKWfzDDJjb"
      },
      "outputs": [],
      "source": [
        "#tomamos nuestros pesos ya entrenado del modelo resnet como tambien solo entrenamos al utltima capa\n",
        "model_c = ModelCustom(pretrained=True, freeze=True)\n",
        "fit(model_c, dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EN NUESTRO PRIMER ENTRENAMIENTO NOTAMOS QUE PRESENTAMOS CON 5 EPOCH UN RESULTADO DE CASI 98% TENEMOS UNA PERDIDAD DEL 12% Y UNA GANANCIAS DE VALIDACION DE 98%"
      ],
      "metadata": {
        "id": "aG2JwB2vU5MM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UCXpGmNDJjb"
      },
      "source": [
        "Como puedes ver no sólo obtenemos un mejor modelo en menos *epochs* sino que además cada *epoch* tarda menos en completarse. Esto es debido a que, al no estar entrenando gran parte de la red, los requisitos computacionales se reducen considerablemente. Mejores modelos y entrenados más rápido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZNKl_oUDJjb"
      },
      "source": [
        "## Fine Tuning\n",
        "es una técnica que se utiliza en el aprendizaje profundo para mejorar el rendimiento de una red neuronal pre-entrenada para una tarea específica. El objetivo es ajustar los pesos de la red pre-entrenada en una tarea relacionada con la tarea que queremos resolver, permitiendo que la red aprenda a reconocer patrones más específicos en los datos de entrada.\n",
        "\n",
        "Todavía podemos mejorar un poco más si, además de utilizar los pesos descargados de Imagenet en `resnet`, entrenamos también la red completa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmSMJy9SDJjb"
      },
      "outputs": [],
      "source": [
        "#DE IGUAL FORMA TENEMOS EL FINE TUNING QUE NOS PERMITE UN MEJORA DE RENDIMIENTO\n",
        "#DONDE INTRODUCIMOS LOS PESOS YA ENTRENADOS DE NUESTRO MODELO Y ADEMA ENTRENAMOS TODAS LAS CAPAS DEL MODELO\n",
        "model_c = ModelCustom(pretrained=True, freeze=False)\n",
        "fit(model_c, dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXqoY3ayDJjc"
      },
      "source": [
        "Es común entrenar primero el modelo sin entrenar la red pre-entrenada durante varias epochs y después seguir entrenando, pero permitiendo ahora la actualización de pesos también en la red pre-entrenada (usualmente con un *learning rate* más pequeño)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBc7f5T_DJjc"
      },
      "outputs": [],
      "source": [
        "model_o = ModelCustom(pretrained=True, freeze=True)\n",
        "fit(model_o, dataloader,epochs=5)\n",
        "model_o.unfreeze()\n",
        "fit(model_o, dataloader, epochs=5, lr=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wYIYY1EDJjc"
      },
      "source": [
        "Otra alternativa de *fine tuning* es la de entrenar el modelo con diferentes *learning rates*, uno para la red pre-entrenada y otro para las capas nuevas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80sdLTXUDJjc"
      },
      "outputs": [],
      "source": [
        "\n",
        "#UTILIZAMOS Y PROBAMOS CON LERNIGN REIGHT DISTINTO AL PRINCIPO\n",
        "optimizer = torch.optim.Adam([\n",
        "    {'params': model_o.resnet.parameters(), 'lr': 1e-3},\n",
        "    {'params': model_o.fc.parameters(), 'lr': 1e-2}\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ku9sSkmcGZVI"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def fit(model, dataloader, epochs=5, lr_resnet=1e-4, lr_fc=1e-3):\n",
        "    model.to(device)\n",
        "    optimizer = optimizer = torch.optim.Adam([{'params': model.resnet.parameters(), 'lr': lr_resnet},{'params': model.fc.parameters(), 'lr': lr_fc}])\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        train_loss, train_acc = [], []\n",
        "        bar = tqdm(dataloader['train'])\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "            train_acc.append(acc)\n",
        "            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n",
        "        bar = tqdm(dataloader['test'])\n",
        "        val_loss, val_acc = [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in bar:\n",
        "                X, y = batch\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                y_hat = model(X)\n",
        "                loss = criterion(y_hat, y)\n",
        "                val_loss.append(loss.item())\n",
        "                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "                val_acc.append(acc)\n",
        "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
        "        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IX60uex6HGMh"
      },
      "outputs": [],
      "source": [
        "model_o = ModelCustom(pretrained=True, freeze=True)#pretraindes pesos del modelo, freeze=true que entrenamos la ultima cap\n",
        "fit(model_o, dataloader, lr_resnet=1e-4, lr_fc=1e-3)\n",
        "model_o.unfreeze()#ahora cambia a que entrenamoso todas las capas\n",
        "fit(model_o, dataloader, lr_resnet=1e-4, lr_fc=1e-3)#entrenemos ahora con todas las capas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TENIENDO NUESTRO MODELO ENTRENADO CON LEARNING REIGTH DIFERENTE DONDE DA UN DICHOSO 99% DE PRECISION DE ENTRENAMIENTO Y UNA PERDIDA DE MENOS DE 1% PRESENTANDO UN EFICACIA DE ENTRENAMIENTO SOBRE LAS IMAGENES DE ESTE DATA SET"
      ],
      "metadata": {
        "id": "Mhf5Y__SV9dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualizacionEntrenamiento(model, dataloader):\n",
        "    model.eval()\n",
        "    count = 0\n",
        "    fig, axs = plt.subplots(4, 5, figsize=(10, 8))\n",
        "    fig.subplots_adjust(hspace=0.5, wspace=0.5)\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            X, y = batch\n",
        "            X = X.to('cuda')\n",
        "            y_pred = model(X)\n",
        "            y_pred = torch.argmax(y_pred, axis=1)\n",
        "            y = y.to('cuda')\n",
        "            images = X.permute(0, 2, 3, 1).cpu().numpy()\n",
        "            for i in range(images.shape[0]):\n",
        "                if count >= 20:\n",
        "                    break\n",
        "                image = images[i]\n",
        "                label = y[i].item()\n",
        "                prediction = y_pred[i].item()\n",
        "                row = count // 5\n",
        "                col = count % 5\n",
        "                axs[row, col].imshow(image)\n",
        "                axs[row, col].set_title(f\"img orig: {label},\\n img predict: {prediction}\")\n",
        "                axs[row, col].axis('off')\n",
        "                count += 1\n",
        "            if count >= 20:\n",
        "                break\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1j8Uq68Pqc96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualizacionEntrenamiento(model_o, dataloader['test'])"
      ],
      "metadata": {
        "id": "yLCaxB4nqrM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlbRHxL3DJjc"
      },
      "source": [
        "## Resumen\n",
        "\n",
        "En este post hemos visto como podemos llevar a cabo *transfer learning* con redes convolucionales. Aplicar esta técnica nos permitirá obtener mejores modelos con menos requisitos computacionales y con datasets reducidos. Podemos descargar una red pre-entrenada con otro dataset (idealmente, un dataset similar al nuestro) y aprovechar el máximo número de capas. Podemos *congelar* la red pre-entrenada, de manera que no se actualicen sus pesos durante el entrenamiento, y utilizarla solo como extractor de características que las nuevas capas (las cuales si entrenamos) pueden aprovechar. Aún así, hacer *fine tuning* (seguir entrenando la red pre-entrenada) puede dar como resultado un mejor modelo. El *transfer learning* es una técnica muy potente que siempre que podamos podemos aprovechar para reducir los requisitos computacionales de nuestros modelos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "233.594px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}